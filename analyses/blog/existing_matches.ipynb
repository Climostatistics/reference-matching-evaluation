{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing existing and new links\n",
    "\n",
    "Dominika Tkaczyk\n",
    "\n",
    "22.11.2018\n",
    "\n",
    "In this analysis I examine how the links existing in the live system compare to the links currently returned by STQ and SBM(V) algorithms.\n",
    "\n",
    "The results from this notebook were published on [Crossref blog](https://www.crossref.org/blog/reference-matching-for-real-this-time/).\n",
    "\n",
    "For the comparison of the algorithms on automatically generated reference strings, see [this notebook](https://github.com/CrossRef/reference-matching-evaluation/blob/master/analyses/blog/comparison.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TL;DR\n",
    "\n",
    "  * The dataset used in this analysis is composed of 2000 random reference strings from the live system. For each string I have:\n",
    "    * original link (currently in the system)\n",
    "    * STQ link (the link returned by STQ form)\n",
    "    * SBM link (the link returned by SBM algorithm)\n",
    "    * SBMV link (the link returned by SBMV algorithm)\n",
    "  * Both variations of SBM are outperformed by STQ (F1 92.5% vs. 84.3% and 83.6%).\n",
    "  * **SBMV outperforms STQ (F1 96.3% vs. 92.5%)**, with precision worse by 0.86 percentage points and recall better by 7.71 percentage points. The difference in precision between SBMV and STQ is not statistically significant. The difference in recall between SBMV and STQ is statistically significant.\n",
    "  * SBMV also outperforms the results for the current links (F1 96.3% vs. 77.8%). Applying SBMV to currently not resolved links would result in 51.4% more links, 95.5% of which would be correct.\n",
    "  * There is a high level of agreement between the links (original vs. STQ vs. SBMV):\n",
    "    * in 84.7% of the cases SBM with a simple threshold link is equal to either original or new STQ link\n",
    "    * in 78.0% of the cases SBM with a normalized threshold link is equal to either original or new STQ link\n",
    "    * in 94.0% of the cases SBMV link is equal to either original or new STQ link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "The goal of this analysis is to examine the agreement between the approaches, as well as to estimate precision, recall and F1 on the real data.\n",
    "\n",
    "The following procedure was used to gather the data for these experiments:\n",
    "1. A random sample of 100K items was extracted from the system.\n",
    "2. I iterated over all references in the sampled items, and extracted all unstructured references (reference strings).\n",
    "3. I sampled 2000 unstructured references from them, recorded the existing target DOI (if any), and ran STQ, SBM and SBMV algorithms on them.\n",
    "4. I manually provided ground truth target DOIs for each reference string. This was done by verifying DOIs returned by the algorithms and/or manual searching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import utils.data_format_keys as dfk\n",
    "\n",
    "from dataset.dataset_utils import get_target_gt_doi, get_target_test_doi\n",
    "from evaluation.evaluation_utils import doi_test_same, doi_equals\n",
    "from evaluation.link_metrics import LinkMetricsResults\n",
    "from evaluation.reference_metrics import ReferenceMetricsResults\n",
    "from scipy.stats import chi2_contingency\n",
    "from utils.utils import read_json\n",
    "\n",
    "DATA_DIR = '../../data/blog/existing_links/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision, recall, F1\n",
    "\n",
    "First, let's compare precision, recall and F1 of different algorithms.\n",
    "\n",
    "Here are the results of the links currently present in the system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original precision: 0.9922 (CI at 95% 0.9860-0.9984)\n",
      "original recall: 0.6399 (CI at 95% 0.6126-0.6671)\n",
      "original F1: 0.7780\n"
     ]
    }
   ],
   "source": [
    "def print_summary(dataset, name):\n",
    "    link_results = LinkMetricsResults(dataset)\n",
    "    print('{} precision: {:.4f} (CI at 95% {:.4f}-{:.4f})'\n",
    "          .format(name, link_results.get(dfk.EVAL_PREC),\n",
    "                  link_results.get(dfk.EVAL_CI_PREC)[0], link_results.get(dfk.EVAL_CI_PREC)[1]))\n",
    "    print('{} recall: {:.4f} (CI at 95% {:.4f}-{:.4f})'\n",
    "          .format(name, link_results.get(dfk.EVAL_REC),\n",
    "                  link_results.get(dfk.EVAL_CI_REC)[0], link_results.get(dfk.EVAL_CI_REC)[1]))\n",
    "    print('{} F1: {:.4f}'.format(name, link_results.get(dfk.EVAL_F1)))\n",
    "\n",
    "dataset_orig = read_json(DATA_DIR + 'unstructured_orig.json')[dfk.DATASET_DATASET]\n",
    "print_summary(dataset_orig, 'original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For precision and recall the confidence intervals at the confidence level of 95% are given. The confidence interval is the range of values where the real value is likely to be. For example, based on this, we are 95% sure that the real recall in the system currently is in the range 0.6126-0.6671. More information about the foundations of sampling and confidence intervals can be found in [this notebook](https://github.com/CrossRef/reference-matching-evaluation/blob/master/analyses/sampling_notes.ipynb).\n",
    "\n",
    "Here are the results of STQ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STQ precision: 0.9895 (CI at 95% 0.9833-0.9957)\n",
      "STQ recall: 0.8685 (CI at 95% 0.8493-0.8877)\n",
      "STQ F1: 0.9251\n"
     ]
    }
   ],
   "source": [
    "dataset_stq = read_json(DATA_DIR + 'unstructured_stq.json')[dfk.DATASET_DATASET]\n",
    "print_summary(dataset_stq, 'STQ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to calculate the results for SBM and SBMV, we have to modify the SBM and SBMV datasets according to the best thresholds calculated previously. These functions will modify the dataset according to the simple, normalized or validation threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_simple_threshold(dataset, threshold):\n",
    "    for item in dataset:\n",
    "        if item[dfk.DATASET_SCORE] is not None and item[dfk.DATASET_SCORE] < threshold:\n",
    "            item[dfk.DATASET_TARGET_TEST][dfk.CR_ITEM_DOI] = None\n",
    "    return dataset\n",
    "\n",
    "def modify_norm_threshold(dataset, threshold):\n",
    "    for item in dataset:\n",
    "        if item[dfk.DATASET_SCORE] is not None \\\n",
    "            and item[dfk.DATASET_SCORE]/len(item[dfk.DATASET_REF_STRING]) < threshold:\n",
    "            item[dfk.DATASET_TARGET_TEST][dfk.CR_ITEM_DOI] = None\n",
    "    return dataset\n",
    "\n",
    "def modify_valid_threshold(dataset, threshold):\n",
    "    for item in dataset:\n",
    "        if item[dfk.DATASET_SCORE] is not None and item[dfk.DATASET_SCORE] < threshold:\n",
    "            item[dfk.DATASET_TARGET_TEST][dfk.CR_ITEM_DOI] = None\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the results of SBM with a simple threshold of 64:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBM precision: 0.8686 (CI at 95% 0.8488-0.8883)\n",
      "SBM recall: 0.8191 (CI at 95% 0.7973-0.8409)\n",
      "SBM F1: 0.8431\n"
     ]
    }
   ],
   "source": [
    "dataset_sbm_simple = read_json(DATA_DIR + 'unstructured_sbm.json')[dfk.DATASET_DATASET]\n",
    "modify_simple_threshold(dataset_sbm_simple, 64)\n",
    "print_summary(dataset_sbm_simple, 'SBM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the results of SBM with the normalized threshold of 0.4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBM precision: 0.7712 (CI at 95% 0.7493-0.7932)\n",
      "SBM recall: 0.9121 (CI at 95% 0.8960-0.9281)\n",
      "SBM F1: 0.8358\n"
     ]
    }
   ],
   "source": [
    "dataset_sbm_norm = read_json(DATA_DIR + 'unstructured_sbm.json')[dfk.DATASET_DATASET]\n",
    "modify_norm_threshold(dataset_sbm_norm, 0.4)\n",
    "print_summary(dataset_sbm_norm, 'SBM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, the results of SBMV with the validation threshold of 0.34:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBMV precision: 0.9809 (CI at 95% 0.9730-0.9888)\n",
      "SBMV recall: 0.9456 (CI at 95% 0.9327-0.9584)\n",
      "SBMV F1: 0.9629\n"
     ]
    }
   ],
   "source": [
    "dataset_sbmv = read_json(DATA_DIR + 'unstructured_sbmv.json')[dfk.DATASET_DATASET]\n",
    "modify_simple_threshold(dataset_sbmv, 0.34) \n",
    "print_summary(dataset_sbmv, 'SBMV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare all the results in one plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_means(dataset):\n",
    "    results = LinkMetricsResults(dataset)\n",
    "    return [results.get(m) for m in [dfk.EVAL_PREC, dfk.EVAL_REC, dfk.EVAL_F1]]\n",
    "\n",
    "def get_ci(dataset):\n",
    "    results = LinkMetricsResults(dataset)\n",
    "    ms = [results.get(m) for m in [dfk.EVAL_PREC, dfk.EVAL_REC]]\n",
    "    return [[a-results.get(m)[0] for m, a in zip([dfk.EVAL_CI_PREC, dfk.EVAL_CI_REC], ms)] + [0],\n",
    "            [results.get(m)[1]-a for m, a in zip([dfk.EVAL_CI_PREC, dfk.EVAL_CI_REC], ms)] + [0]]\n",
    "\n",
    "def autolabel(ax, rects):\n",
    "    plt.rcParams.update({'font.size': 10})\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        text = '{:.2f}'.format(height)\n",
    "        text = re.sub('\\.00$', '', text)\n",
    "        ax.text(rect.get_x() + rect.get_width()/2., 1.03*height, text, ha='center', va='bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind = np.arange(3)\n",
    "width = 0.15\n",
    "plt.rcParams.update({'font.size': 15, 'legend.fontsize': 10}) \n",
    "fig, ax = plt.subplots(figsize=(12, 9))\n",
    "\n",
    "rects1 = ax.bar(ind - 1.5 * width, get_means(dataset_orig), yerr=get_ci(dataset_stq), width=width,\n",
    "                color='#d8d2c4')\n",
    "rects2 = ax.bar(ind - 0.5 * width, get_means(dataset_stq), yerr=get_ci(dataset_sbm_simple),\n",
    "                width=width, color='#4f5858')\n",
    "rects3 = ax.bar(ind + 0.5 * width, get_means(dataset_sbm_simple), yerr=get_ci(dataset_sbm_norm),\n",
    "                width=width, color='#3eb1c8')\n",
    "rects4 = ax.bar(ind + 1.5 * width, get_means(dataset_sbm_norm), yerr=get_ci(dataset_sbmv),\n",
    "                width=width, color='#ffc72c')\n",
    "rects5 = ax.bar(ind + 2.5 * width, get_means(dataset_sbmv), yerr=get_ci(dataset_sbmv),\n",
    "                width=width, color='#ef3340')\n",
    "\n",
    "ax.set_ylabel('fraction')\n",
    "ax.set_xticks(ind + width / 2)\n",
    "ax.set_xticklabels(('precision', 'recall', 'F1'))\n",
    "plt.ylim(0, 1.25)\n",
    "plt.yticks([0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "ax.legend((rects1[0], rects2[0], rects3[0], rects4[0], rects5[0]),\n",
    "          ('original', 'STQ', 'SBM (simple threshold)', 'SBM (norm threshold)', 'SBMV'))\n",
    "autolabel(ax, rects1)\n",
    "autolabel(ax, rects2)\n",
    "autolabel(ax, rects3)\n",
    "autolabel(ax, rects4)\n",
    "autolabel(ax, rects5)\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, SBMV outperforms all other algorithms. It is better than STQ (F1 96.29% vs. 92.51%), with precision worse by only 0.86 percentage points and recall better by 7.71 percentage points.\n",
    "\n",
    "Both variations of SBM are much worse than SBMV and STQ.\n",
    "\n",
    "Let's also calculate statistical significance between STQ's and SBMV's precision and recall using a Chi-square test of independence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision p-value: 0.1377 (this is not statistically significant)\n",
      "recall p-value: 0.0000 (this is statistically significant)\n"
     ]
    }
   ],
   "source": [
    "for metric in [dfk.EVAL_PREC, dfk.EVAL_REC]:\n",
    "    fun = get_target_test_doi if metric == dfk.EVAL_PREC else get_target_gt_doi\n",
    "    stq_results = LinkMetricsResults(dataset_stq)\n",
    "    stq_precision = stq_results.get(metric)\n",
    "    stq_test_count = len([d for d in dataset_stq if fun(d) is not None])\n",
    "    stq_precision_success = int(stq_precision * stq_test_count)\n",
    "\n",
    "    sbmv_results = LinkMetricsResults(dataset_sbmv)\n",
    "    sbmv_precision = sbmv_results.get(metric)\n",
    "    sbmv_test_count = len([d for d in dataset_sbmv if fun(d) is not None])\n",
    "    sbmv_precision_success = int(sbmv_precision * sbmv_test_count)\n",
    "\n",
    "    _, p, _, _ = chi2_contingency(np.array([[stq_precision_success,\n",
    "                                             stq_test_count-stq_precision_success],\n",
    "                                           [sbmv_precision_success,\n",
    "                                            sbmv_test_count-sbmv_precision_success]]),\n",
    "                                  correction=True)\n",
    "    c = 'this is statistically significant' if p < 0.05 \\\n",
    "        else 'this is not statistically significant'\n",
    "    print('{} p-value: {:.4f} ({})'.format(metric, p, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference in precision is not statistically significant. In other words, the values are so close that we cannot rule out that the difference is due to the randomness in sampling.\n",
    "\n",
    "The difference in recall is statistically significant.\n",
    "\n",
    "Let's also see what would the validation threshold of SBMV be if we wanted to match STQ's precision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STQ's precision is matched for threshold 0.43\n",
      "Recall for this threshold: 0.9321608040201005\n"
     ]
    }
   ],
   "source": [
    "dataset_sbmv = read_json(DATA_DIR + 'unstructured_sbmv.json')[dfk.DATASET_DATASET]\n",
    "results = [LinkMetricsResults(modify_simple_threshold(dataset_sbmv, t))\n",
    "           for t in np.arange(0, 1, 0.01)]\n",
    "thresholds = np.arange(0, 1, 0.1)\n",
    "precisions = [r.get(dfk.EVAL_PREC) for r in results]\n",
    "recalls = [r.get(dfk.EVAL_REC) for r in results]\n",
    "for i, p in enumerate(precisions):\n",
    "    if p >= 0.9895:\n",
    "        break\n",
    "print('STQ\\'s precision is matched for threshold {}'.format(i/100))\n",
    "print('Recall for this threshold: {}'.format(recalls[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the threshold 0.43 the recall is 93.2%, which is still higher than STQ's recall of 86.9%.\n",
    "\n",
    "Finally, let's see how many more links we would get if we applied SBMV to currently unresolved references in the system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying SBMV to currently not resolved links will result in 51.43% more links\n",
      "95.45% of the new links will be correct\n"
     ]
    }
   ],
   "source": [
    "dataset_sbmv = read_json(DATA_DIR + 'unstructured_sbmv.json')[dfk.DATASET_DATASET]\n",
    "modify_simple_threshold(dataset_sbmv, 0.34) \n",
    "\n",
    "orig_links = len([d for d in dataset_orig if get_target_test_doi(d) is not None])\n",
    "sbmv_new_links = len([d_sbmv for d_orig, d_sbmv in zip(dataset_orig, dataset_sbmv)\n",
    "                      if get_target_test_doi(d_sbmv) is not None\n",
    "                      and get_target_test_doi(d_orig) is None])\n",
    "sbmv_new_correct_links = len([d_sbmv for d_orig, d_sbmv in zip(dataset_orig, dataset_sbmv)\n",
    "                              if get_target_test_doi(d_sbmv) is not None\n",
    "                              and get_target_test_doi(d_orig) is None\n",
    "                              and doi_equals(d_sbmv)])\n",
    "\n",
    "print('Applying SBMV to currently not resolved links will result in {:.2f}% more links'\n",
    "      .format(100*sbmv_new_links/orig_links))\n",
    "print('{:.2f}% of the new links will be correct'\n",
    "      .format(100*sbmv_new_correct_links/sbmv_new_links))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agreement between links\n",
    "\n",
    "Let's also see what is the agreement between the links.\n",
    "\n",
    "Function *get_category* classifies an item from the dataset into one of the categories:\n",
    "  * SBM(V) = STQ = orig (all links agree)\n",
    "  * SBM(V) = STQ =/= orig (original link is different)\n",
    "  * SBM(V) = orig =/= STQ (new STQ link is different)\n",
    "  * SBM(V) =/= STQ = orig (SBM(V) link is different)\n",
    "  * other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['SBM(V) = STQ = orig', 'SBM(V) = STQ =/= orig', 'SBM(V) = orig =/= STQ',\n",
    "              'SBM(V) =/= STQ = orig', 'other']\n",
    "\n",
    "def get_category(item_orig, item_stq, item_new):\n",
    "    if doi_test_same(item_orig, get_target_test_doi(item_stq)) and \\\n",
    "            doi_test_same(item_orig, get_target_test_doi(item_new)):\n",
    "        return 'SBM(V) = STQ = orig'\n",
    "    if doi_equals(item_orig) and doi_equals(item_stq) and doi_equals(item_new):\n",
    "        return 'SBM(V) = STQ = orig'\n",
    "    if doi_test_same(item_new, get_target_test_doi(item_stq)) and \\\n",
    "            not doi_test_same(item_new, get_target_test_doi(item_orig)):\n",
    "        return 'SBM(V) = STQ =/= orig'\n",
    "    if not doi_equals(item_orig) and doi_equals(item_stq) and doi_equals(item_new):\n",
    "        return 'SBM(V) = STQ =/= orig'\n",
    "    if doi_test_same(item_new, get_target_test_doi(item_orig)) and \\\n",
    "            not doi_test_same(item_new, get_target_test_doi(item_stq)):\n",
    "        return 'SBM(V) = orig =/= STQ'\n",
    "    if doi_equals(item_orig) and not doi_equals(item_stq) and doi_equals(item_new):\n",
    "        return 'SBM(V) = orig =/= STQ'\n",
    "    if doi_test_same(item_stq, get_target_test_doi(item_orig)) and \\\n",
    "            not doi_test_same(item_new, get_target_test_doi(item_stq)):\n",
    "        return 'SBM(V) =/= STQ = orig'\n",
    "    if doi_equals(item_orig) and doi_equals(item_stq) and not doi_equals(item_new):\n",
    "        return 'SBM(V) =/= STQ = orig'\n",
    "    return 'other'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the distribution of the categories in the dataset for the best simple threshold of SBM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SBM(V) = STQ = orig': 0.684,\n",
       " 'SBM(V) = STQ =/= orig': 0.122,\n",
       " 'SBM(V) = orig =/= STQ': 0.0405,\n",
       " 'SBM(V) =/= STQ = orig': 0.1475,\n",
       " 'other': 0.006}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_orig = read_json(DATA_DIR + 'unstructured_orig.json')[dfk.DATASET_DATASET]\n",
    "dataset_stq = read_json(DATA_DIR + 'unstructured_stq.json')[dfk.DATASET_DATASET]\n",
    "dataset_sbm = read_json(DATA_DIR + 'unstructured_sbm.json')[dfk.DATASET_DATASET]\n",
    "modify_simple_threshold(dataset_sbm, 64)\n",
    "\n",
    "data_categories = [get_category(d1, d2, d3)\n",
    "                   for d1, d2, d3 in zip(dataset_orig, dataset_stq, dataset_sbm)]\n",
    "categories_counts = {cat: data_categories.count(cat)/len(data_categories) for cat in categories}\n",
    "categories_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 68.4% of the cases all links agree and in 84.65% SBM link is equal to either original or STQ link.\n",
    "\n",
    "What about the distribution of the categories in the dataset for the best normalized threshold of SBM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SBM(V) = STQ = orig': 0.6215,\n",
       " 'SBM(V) = STQ =/= orig': 0.1435,\n",
       " 'SBM(V) = orig =/= STQ': 0.0145,\n",
       " 'SBM(V) =/= STQ = orig': 0.21,\n",
       " 'other': 0.0105}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_orig = read_json(DATA_DIR + 'unstructured_orig.json')[dfk.DATASET_DATASET]\n",
    "dataset_stq = read_json(DATA_DIR + 'unstructured_stq.json')[dfk.DATASET_DATASET]\n",
    "dataset_sbm = read_json(DATA_DIR + 'unstructured_sbm.json')[dfk.DATASET_DATASET]\n",
    "modify_norm_threshold(dataset_sbm, 0.4)\n",
    "\n",
    "data_categories = [get_category(d1, d2, d3)\n",
    "                   for d1, d2, d3 in zip(dataset_orig, dataset_stq, dataset_sbm)]\n",
    "categories_counts = {cat: data_categories.count(cat)/len(data_categories) for cat in categories}\n",
    "categories_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 62.15% of the cases all links agree and in 77.95% SBM link is equal to either original or STQ link.\n",
    "\n",
    "What about the distribution of the categories in the dataset for the best validation threshold of SBMV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SBM(V) = STQ = orig': 0.773,\n",
       " 'SBM(V) = STQ =/= orig': 0.148,\n",
       " 'SBM(V) = orig =/= STQ': 0.019,\n",
       " 'SBM(V) =/= STQ = orig': 0.0585,\n",
       " 'other': 0.0015}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_orig = read_json(DATA_DIR + 'unstructured_orig.json')[dfk.DATASET_DATASET]\n",
    "dataset_stq = read_json(DATA_DIR + 'unstructured_stq.json')[dfk.DATASET_DATASET]\n",
    "dataset_sbmv = read_json(DATA_DIR + 'unstructured_sbmv.json')[dfk.DATASET_DATASET]\n",
    "modify_simple_threshold(dataset_sbmv, 0.34)\n",
    "\n",
    "data_categories = [get_category(d1, d2, d3)\n",
    "                   for d1, d2, d3 in zip(dataset_orig, dataset_stq, dataset_sbmv)]\n",
    "categories_counts = {cat: data_categories.count(cat)/len(data_categories) for cat in categories}\n",
    "categories_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 77.3% of the cases all links agree and in 94.0% SBMV link is equal to either original or STQ link."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error analysis\n",
    "\n",
    "Let's also look more closely at the causes of SBMV errors in our 2000 references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 2000\n"
     ]
    }
   ],
   "source": [
    "data = read_json(DATA_DIR + 'comparison-reasons.json')\n",
    "sbm_link = 'search_API_link'\n",
    "sbm_score = 'search_API_score'\n",
    "gt_link = 'gt'\n",
    "res = [d.update({sbm_link: None}) for d in data\n",
    "       if d[sbm_score] is not None and d[sbm_score] < 0.34]\n",
    "print('Dataset size: {}'.format(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many references were correctly matched?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly resolved references: 1129 (56.45%)\n"
     ]
    }
   ],
   "source": [
    "data_correct_res = [d for d in data if d[sbm_link] == d[gt_link] and d[sbm_link] is not None]\n",
    "print('Correctly resolved references: {} ({:.2f}%)'.format(len(data_correct_res),\n",
    "                                                           100*len(data_correct_res)/len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many references were correctly not matched to anything?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly not resolved references: 791 (39.55%)\n"
     ]
    }
   ],
   "source": [
    "data_correct_not_res = [d for d in data if d[sbm_link] == d[gt_link] and d[sbm_link] is None]\n",
    "print('Correctly not resolved references: {} ({:.2f}%)'\n",
    "      .format(len(data_correct_not_res), 100*len(data_correct_not_res)/len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are left with 80 reference strings incorrectly matched or unmatched.\n",
    "\n",
    "How many references are matched to the wrong document?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "References resolved to the wrong document: 7 (0.35%)\n"
     ]
    }
   ],
   "source": [
    "data_incorrect_res = [d for d in data if d[sbm_link] != d[gt_link] and d[sbm_link] is not None\n",
    "                      and d[gt_link] is not None]\n",
    "print('References resolved to the wrong document: {} ({:.2f}%)'\n",
    "      .format(len(data_incorrect_res), 100*len(data_incorrect_res)/len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the summary of the causes of these errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('similar metadata', 2),\n",
       " ('no title in the ref string', 2),\n",
       " ('two similar papers differ by journal name only', 1),\n",
       " ('search score too low to be considered as a candidate', 1),\n",
       " ('chapter matched instead of the book', 1)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def summarize_causes(data):\n",
    "    causes = [d['reason'] for d in data]\n",
    "    causes = list(set([(r, causes.count(r)) for r in causes]))\n",
    "    causes.sort(key=lambda x: x[1], reverse=True) \n",
    "    return causes\n",
    "\n",
    "summarize_causes(data_incorrect_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have only 7 cases. In two cases the mistake was caused by missing title in the reference string. In one case the right target's relevance score was too low, and the remaining four reference strings were matched to similar documents.\n",
    "\n",
    "How many missing links we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing links: 58 (2.90%)\n"
     ]
    }
   ],
   "source": [
    "data_incorrect_not_res = [d for d in data if d[sbm_link] is None and d[gt_link] is not None]\n",
    "print('Missing links: {} ({:.2f}%)'\n",
    "      .format(len(data_incorrect_not_res), 100*len(data_incorrect_not_res)/len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the largest category of the errors. What were the causes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('missing author in the metadata', 8),\n",
       " ('search score too low to be considered as a candidate', 7),\n",
       " ('missing year in the metadata', 7),\n",
       " ('year mismatch', 5),\n",
       " ('missing year and pages in the metadata', 4),\n",
       " ('DOI resolvable but not visible in API', 4),\n",
       " ('missing author in the ref string', 4),\n",
       " ('no numbers in the ref string except for arXiv id', 4),\n",
       " ('search score too low to be considered as a candidate; no title in the ref string',\n",
       "  3),\n",
       " ('missing title in the metadata', 2),\n",
       " ('missing title in the ref string', 2),\n",
       " ('ref string contains a large HTML fragment', 2),\n",
       " ('no title or numbers in the ref string', 1),\n",
       " (\"author's entire name as family name in the metadata, ref string contains abbreviated first name\",\n",
       "  1),\n",
       " ('missing year in the ref string', 1),\n",
       " ('matcher error', 1),\n",
       " ('title given in different language in the ref string', 1),\n",
       " ('missing author in the ref string, missing year in the metadata', 1)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_causes(data_incorrect_not_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common causes are:\n",
    "  * the target was scored too low by the search engine\n",
    "  * missing metadata in the items in the system\n",
    "  * missing information in the reference strings\n",
    "  \n",
    "Finally, how many unexpected links we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect extra links: 15 (0.75%)\n"
     ]
    }
   ],
   "source": [
    "data_incorrect_extra_res = [d for d in data if d[sbm_link] is not None and d[gt_link] is None]\n",
    "print('Incorrect extra links: {} ({:.2f}%)'\n",
    "      .format(len(data_incorrect_extra_res), 100*len(data_incorrect_extra_res)/len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 15 extra links. What were the causes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('multiple references in the string', 6),\n",
       " ('similar metadata', 4),\n",
       " ('journal article matched; chapter/book referenced', 2),\n",
       " ('different versions of the paper', 1),\n",
       " ('conference paper matched; phd thesis referenced', 1),\n",
       " ('journal article matched; working paper referenced', 1)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_causes(data_incorrect_extra_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common cases are:\n",
    "  * Sometimes the reference string contains multiple references, either intentionally or by mistake. In such cases we expect the matching algorithm not to return any match, but sometimes the match is found.\n",
    "  * Reference strings containing similar metadata as the matched items, while the referenced version of the document is not present in the system."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
