{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes on sampling\n",
    "\n",
    "Dominika Tkaczyk\n",
    "\n",
    "4.09.2018\n",
    "\n",
    "This notebook contains some basic experiments related to data sampling. The main purpose of this is to convince myself (and hopefully wider audience) that we can safely calculate things on samples of the data rather than on all the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TL;DR\n",
    "\n",
    "  * Sampling is a standard way of estimating the average value of a certain feature by calculating it only for a random sample, not for the entire population of items. Note that estimating =/= guessing.\n",
    "  * Confidence intervals provide a way of controling the amount of uncertainty related to randomness in sampling. Confidence interval is calculated from a sample and has a form (estimated value - something, estimated value + something). An important parameter is confidence level, which we use to specify how certain we want to be about our interval.\n",
    "  * Confidence interval at level 95% is interpreted as follows: we are 95% sure that the real value that we are estimating is within our calculated confidence interval.\n",
    "  * The higher the confidence level (i.e. the more certain we want to be about the interval), the wider the interval has to be.\n",
    "  * The larger the sample, the narrower the confidence interval.\n",
    "  * We are never sure that the value we are estimating is actually within our calculated confidence interval. By setting the confidence level high, we just make sure this is an unlikely event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "First let's define some basic terms:\n",
    "  * **population** - this is the complete set of \"items\" or \"things\" we are interested in. In statistics this is often a group of people (hence the term), for example the entire population of USA. In my experiments, the population is the entire set of metadata records (works) in Crossref system (100M records).\n",
    "  * **sample** - a subset of items randomly chosen from the population. Its most important parameter is the size.\n",
    "  * **statistic** - a numeric feature of the item. Examples: the age of a person, the number of authors listed in the metadata record, the length of the title.\n",
    "  * **population average** - the average value of a statistic in the population.\n",
    "  * **sample average** - the average value of a statistic in the sample.\n",
    "\n",
    "In these experiments, we want to know the population average of a certain statistic. Depending on the size of the population, and how difficult it is to calculate the statistic, calculating the population average directly might not be fast enough or even possible. In such cases, one alternative is to use sampling to estimate the population average. Note that estimating =/= guessing.\n",
    "\n",
    "Let's import some stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from crossref.restful import Works, Etiquette\n",
    "from multiprocessing import Pool\n",
    "from statistics import mean, stdev\n",
    "from utils.cr_utils import get_sample\n",
    "\n",
    "import json\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import re\n",
    "import scipy.stats as st\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will also politely introduce myself to Crossref API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "works = Works(etiquette=Etiquette('Dominika\\'s experiments', '0.1', '', 'dtkaczyk@crossref.org'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating the average number of references\n",
    "\n",
    "I chose a very simple statistic to play with: the number of references, as reported by *references-count* field in the metadata record. Later, I will do some additional experiments with a more complicated statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ref_count(work):\n",
    "    return work['references-count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The exact number\n",
    "\n",
    "The average number of references over the entire population can be, of course, calculated directly. It takes about 3 hours to iterate over the entire dataset (without parallel processing). This code needs access to snapshot of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01% done (average ref count so far 0.0031)\n",
      "0.02% done (average ref count so far 0.0015)\n",
      "0.03% done (average ref count so far 0.0010)\n",
      "0.04% done (average ref count so far 0.0008)\n",
      "0.05% done (average ref count so far 0.0006)\n",
      "0.06% done (average ref count so far 0.0006)\n",
      "0.07% done (average ref count so far 0.0005)\n",
      "0.08% done (average ref count so far 0.0004)\n",
      "0.09% done (average ref count so far 0.0004)\n",
      "0.1% done (average ref count so far 0.0003)\n",
      "0.11% done (average ref count so far 0.0003)\n",
      "0.12% done (average ref count so far 0.0003)\n",
      "0.13% done (average ref count so far 0.0003)\n",
      "0.14% done (average ref count so far 0.0002)\n",
      "0.15% done (average ref count so far 0.0002)\n",
      "0.16% done (average ref count so far 0.0002)\n",
      "0.17% done (average ref count so far 0.0002)\n",
      "0.18% done (average ref count so far 0.0002)\n",
      "0.19% done (average ref count so far 0.0002)\n",
      "0.2% done (average ref count so far 0.0002)\n",
      "0.21% done (average ref count so far 0.0002)\n",
      "0.22% done (average ref count so far 0.0002)\n",
      "0.23% done (average ref count so far 0.0001)\n",
      "0.24% done (average ref count so far 0.0196)\n",
      "0.25% done (average ref count so far 0.0188)\n",
      "0.26% done (average ref count so far 0.0181)\n",
      "0.27% done (average ref count so far 0.0174)\n",
      "0.28% done (average ref count so far 0.0168)\n",
      "0.29% done (average ref count so far 0.0162)\n",
      "0.3% done (average ref count so far 0.0157)\n",
      "0.31% done (average ref count so far 0.0152)\n",
      "0.32% done (average ref count so far 0.0147)\n",
      "0.33% done (average ref count so far 0.0143)\n",
      "0.34% done (average ref count so far 0.0139)\n",
      "0.35% done (average ref count so far 0.0135)\n",
      "0.36% done (average ref count so far 0.0131)\n",
      "0.37% done (average ref count so far 0.0127)\n",
      "0.38% done (average ref count so far 0.0124)\n",
      "0.39% done (average ref count so far 0.0121)\n",
      "0.4% done (average ref count so far 0.0118)\n",
      "0.41% done (average ref count so far 0.0115)\n",
      "0.42% done (average ref count so far 0.0112)\n",
      "0.43% done (average ref count so far 0.0110)\n",
      "0.44% done (average ref count so far 0.0107)\n",
      "0.45% done (average ref count so far 0.0105)\n",
      "0.46% done (average ref count so far 0.0102)\n",
      "0.47% done (average ref count so far 0.0100)\n",
      "0.48% done (average ref count so far 0.0098)\n",
      "0.49% done (average ref count so far 0.0096)\n",
      "0.5% done (average ref count so far 0.0094)\n",
      "0.51% done (average ref count so far 0.0149)\n",
      "0.52% done (average ref count so far 0.0146)\n",
      "0.53% done (average ref count so far 0.0143)\n",
      "0.54% done (average ref count so far 0.0140)\n",
      "0.55% done (average ref count so far 0.0138)\n",
      "0.56% done (average ref count so far 0.0136)\n",
      "0.57% done (average ref count so far 0.0134)\n",
      "0.58% done (average ref count so far 0.0201)\n",
      "0.59% done (average ref count so far 0.0403)\n",
      "0.6% done (average ref count so far 0.0921)\n",
      "0.61% done (average ref count so far 0.3559)\n",
      "0.62% done (average ref count so far 0.7003)\n",
      "0.63% done (average ref count so far 0.9642)\n",
      "0.64% done (average ref count so far 1.2084)\n",
      "0.65% done (average ref count so far 1.4998)\n",
      "0.66% done (average ref count so far 1.6319)\n",
      "0.67% done (average ref count so far 1.8044)\n",
      "0.68% done (average ref count so far 1.9581)\n",
      "0.69% done (average ref count so far 2.0663)\n",
      "0.7% done (average ref count so far 2.3165)\n",
      "0.71% done (average ref count so far 2.5473)\n",
      "0.72% done (average ref count so far 2.6996)\n",
      "0.73% done (average ref count so far 2.8517)\n",
      "0.74% done (average ref count so far 2.9678)\n",
      "0.75% done (average ref count so far 3.0606)\n",
      "0.76% done (average ref count so far 3.1528)\n",
      "0.77% done (average ref count so far 3.2461)\n",
      "0.78% done (average ref count so far 3.3567)\n",
      "0.79% done (average ref count so far 3.3624)\n",
      "0.8% done (average ref count so far 3.4432)\n",
      "0.81% done (average ref count so far 3.5243)\n",
      "0.82% done (average ref count so far 3.6195)\n",
      "0.83% done (average ref count so far 3.8437)\n",
      "0.84% done (average ref count so far 4.0065)\n",
      "0.85% done (average ref count so far 4.3335)\n",
      "0.86% done (average ref count so far 4.8811)\n",
      "0.87% done (average ref count so far 4.9407)\n",
      "0.88% done (average ref count so far 4.9124)\n",
      "0.89% done (average ref count so far 4.8805)\n",
      "0.9% done (average ref count so far 4.8492)\n",
      "0.91% done (average ref count so far 4.8178)\n",
      "0.92% done (average ref count so far 4.7858)\n",
      "0.93% done (average ref count so far 4.7544)\n",
      "0.94% done (average ref count so far 4.7225)\n",
      "0.95% done (average ref count so far 4.7032)\n",
      "0.96% done (average ref count so far 4.6786)\n",
      "0.97% done (average ref count so far 4.8399)\n",
      "0.98% done (average ref count so far 5.0031)\n",
      "0.99% done (average ref count so far 5.1938)\n",
      "1.0% done (average ref count so far 5.3752)\n",
      "1.01% done (average ref count so far 5.4540)\n",
      "1.02% done (average ref count so far 5.6089)\n",
      "1.03% done (average ref count so far 5.9287)\n",
      "1.04% done (average ref count so far 6.4061)\n",
      "1.05% done (average ref count so far 6.8888)\n",
      "1.06% done (average ref count so far 7.1605)\n",
      "1.07% done (average ref count so far 7.2104)\n",
      "1.08% done (average ref count so far 7.2828)\n",
      "1.09% done (average ref count so far 7.2878)\n",
      "1.1% done (average ref count so far 7.2886)\n",
      "1.11% done (average ref count so far 7.3550)\n",
      "1.12% done (average ref count so far 7.5879)\n",
      "1.13% done (average ref count so far 8.0164)\n",
      "1.14% done (average ref count so far 8.4406)\n",
      "1.15% done (average ref count so far 8.6543)\n",
      "1.16% done (average ref count so far 8.6335)\n",
      "1.17% done (average ref count so far 8.8929)\n",
      "1.18% done (average ref count so far 8.9889)\n",
      "1.19% done (average ref count so far 8.9133)\n",
      "1.2% done (average ref count so far 8.9708)\n",
      "1.21% done (average ref count so far 9.1717)\n",
      "1.22% done (average ref count so far 9.3288)\n",
      "1.23% done (average ref count so far 9.2693)\n",
      "1.24% done (average ref count so far 9.2956)\n",
      "1.25% done (average ref count so far 9.3980)\n",
      "1.26% done (average ref count so far 9.6658)\n",
      "1.27% done (average ref count so far 9.6745)\n",
      "1.28% done (average ref count so far 9.7110)\n",
      "1.29% done (average ref count so far 9.6774)\n",
      "1.3% done (average ref count so far 9.6322)\n",
      "1.31% done (average ref count so far 9.7055)\n",
      "1.32% done (average ref count so far 9.7961)\n",
      "1.33% done (average ref count so far 9.8293)\n",
      "1.34% done (average ref count so far 9.8532)\n",
      "1.35% done (average ref count so far 10.0284)\n",
      "1.36% done (average ref count so far 10.1213)\n",
      "1.37% done (average ref count so far 10.2275)\n",
      "1.38% done (average ref count so far 10.3378)\n",
      "1.39% done (average ref count so far 10.4718)\n",
      "1.4% done (average ref count so far 10.5841)\n",
      "1.41% done (average ref count so far 10.7390)\n",
      "1.42% done (average ref count so far 10.8826)\n",
      "1.43% done (average ref count so far 10.9919)\n",
      "1.44% done (average ref count so far 11.0934)\n",
      "1.45% done (average ref count so far 11.2180)\n",
      "1.46% done (average ref count so far 11.3697)\n",
      "1.47% done (average ref count so far 11.4235)\n",
      "1.48% done (average ref count so far 11.5600)\n",
      "1.49% done (average ref count so far 11.6864)\n",
      "1.5% done (average ref count so far 11.8598)\n",
      "...\n",
      "98.51% done (average ref count so far 11.5540)\n",
      "98.52% done (average ref count so far 11.5533)\n",
      "98.53% done (average ref count so far 11.5522)\n",
      "98.54% done (average ref count so far 11.5521)\n",
      "98.55% done (average ref count so far 11.5511)\n",
      "98.56% done (average ref count so far 11.5499)\n",
      "98.57% done (average ref count so far 11.5490)\n",
      "98.58% done (average ref count so far 11.5481)\n",
      "98.59% done (average ref count so far 11.5470)\n",
      "98.6% done (average ref count so far 11.5462)\n",
      "98.61% done (average ref count so far 11.5451)\n",
      "98.62% done (average ref count so far 11.5441)\n",
      "98.63% done (average ref count so far 11.5429)\n",
      "98.64% done (average ref count so far 11.5417)\n",
      "98.65% done (average ref count so far 11.5406)\n",
      "98.66% done (average ref count so far 11.5394)\n",
      "98.67% done (average ref count so far 11.5382)\n",
      "98.68% done (average ref count so far 11.5371)\n",
      "98.69% done (average ref count so far 11.5359)\n",
      "98.7% done (average ref count so far 11.5347)\n",
      "98.71% done (average ref count so far 11.5336)\n",
      "98.72% done (average ref count so far 11.5324)\n"
     ]
    }
   ],
   "source": [
    "def iterate_files(filename):\n",
    "    tar = tarfile.open(filename, 'r:gz')\n",
    "    for member in tar:\n",
    "        f = tar.extractfile(member)\n",
    "        if f is not None:\n",
    "            yield json.load(f)\n",
    "\n",
    "def iterate_items(filename):\n",
    "    for f in iterate_files(filename):\n",
    "        for item in f['items']:\n",
    "            yield item\n",
    "\n",
    "records = 1e8\n",
    "count = 0\n",
    "total = 0\n",
    "for item in iterate_items('/srv/data/snapshots/data-2018-08.tar.gz'):\n",
    "    total = total + ref_count(item)\n",
    "    count = count + 1\n",
    "    if count % 1e4 == 0:\n",
    "        print('{}% done (average ref count so far {:.4f})'.format(100*count/records, total/count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average references count for 98728842 works: 11.5320\n"
     ]
    }
   ],
   "source": [
    "print('Average references count for {} works: {:.4f}'.format(count, total/count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The population average of number of references, as reported by \"references-count\" field, is 11.53."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample distribution\n",
    "\n",
    "Let's play with sampling now and see whether (and how well) we can estimate the population average without processing the entire dataset. We will randomly choose a sample of size 50 from our dataset and calculate the number of references for every element in the sample. This 50-point distribution is called a **sample distribution**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0 0 0 0 0 0 0 0 0 26 0 0 13 0 0 0 0 0 7 0 13 54 31 68 46 19 10 0 0 49 0 0 7 39 0 17 1 0 1 20 52 0 0 39 0 0 24 0 0 8'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sample_distribution(size, stat_fun):\n",
    "    sample = []\n",
    "    while size > 100:\n",
    "        sample.extend(works.sample(100))\n",
    "        size = size - 100\n",
    "    sample.extend(works.sample(size))\n",
    "    return [stat_fun(s) for s in sample]\n",
    "\n",
    "sample = get_sample_distribution(50, ref_count)\n",
    "\" \".join([str(s) for s in sample])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now calculate the sample average and use this number as the estimate of the population average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.88"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, this is not the real population average, only the estimate. How close is it to the population average?\n",
    "\n",
    "In this case we know the answer because I calculated the real population average, but usually we have only the sample and the sample average. Of course, we cannot know where our sampled data points are in the overall population. It is possible that, just by chance, we sampled 50 data points with the highest number of references. Such a sample obviously wouldn't give a good estimate of the population average. On the other hand, we could have drawn a sample with the average very close to the population average. This uncertainty related to sampling randomness can be captured by confidence intervals. Intuitively, confidence intervals let us control the amount of uncertainty related to sampling.\n",
    "\n",
    "Confidence intervals work as follows. We choose the confidence level (a number between 0 and 1). The confidence level roughly means \"how certain we want to be about the estimation\". Based on the chosen confidence level and sample size we then calculate the confidence interval. Confidence interval is the range, in which we expect the true population average to be. Sample average is always in the middle of that range, and the range has the form (sample average - something, sample average + something)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.784913284241135, 15.975086715758867)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def confidence_interval(sample, confidence_level):\n",
    "    return st.t.interval(confidence_level, len(sample)-1, loc=mean(sample), scale=st.sem(sample))\n",
    "\n",
    "ci = confidence_interval(sample, .95)\n",
    "ci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This confidence interval is interpreted as follows: we are 95% sure that the average number of references in the population is within the confidence interval. We will never be 100% using sampling, but this is a decent way to control uncertainty.\n",
    "\n",
    "What happens if we vary the required confidence level?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the sample of size 50, we are 70.0% sure that the population average is in the range 8.2241-13.5359 (estimate 10.8800)\n",
      "Based on the sample of size 50, we are 90.0% sure that the population average is in the range 6.6293-15.1307 (estimate 10.8800)\n",
      "Based on the sample of size 50, we are 95.0% sure that the population average is in the range 5.7849-15.9751 (estimate 10.8800)\n",
      "Based on the sample of size 50, we are 99.0% sure that the population average is in the range 4.0852-17.6748 (estimate 10.8800)\n"
     ]
    }
   ],
   "source": [
    "for cl in [0.7, 0.9, 0.95, 0.99]:\n",
    "    ci = confidence_interval(sample, cl)\n",
    "    print('Based on the sample of size {}, we are {}% sure that the population average is in the range {:.4f}-{:.4f} (estimate {:.4f})'.\n",
    "          format(len(sample), 100 * cl, ci[0], ci[1], mean(sample)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more confident we want to be about the range, the wider we have to make it. This should make intuitive sense.\n",
    "\n",
    "What if we vary the sample size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the sample of size 25, we are 95.0% sure that the population average is in the range -0.2178-17.2578 (estimate 8.5200)\n",
      "Based on the sample of size 50, we are 95.0% sure that the population average is in the range 6.9232-17.9968 (estimate 12.4600)\n",
      "Based on the sample of size 100, we are 95.0% sure that the population average is in the range 7.8374-15.5026 (estimate 11.6700)\n",
      "Based on the sample of size 200, we are 95.0% sure that the population average is in the range 7.3968-13.7332 (estimate 10.5650)\n",
      "Based on the sample of size 400, we are 95.0% sure that the population average is in the range 7.9534-13.2166 (estimate 10.5850)\n",
      "Based on the sample of size 800, we are 95.0% sure that the population average is in the range 9.5761-12.3939 (estimate 10.9850)\n"
     ]
    }
   ],
   "source": [
    "cl = 0.95\n",
    "for size in [25, 50, 100, 200, 400, 800]:\n",
    "    sample = get_sample_distribution(size, ref_count)\n",
    "    ci = confidence_interval(sample, cl)\n",
    "    print('Based on the sample of size {}, we are {}% sure that the population average is in the range {:.4f}-{:.4f} (estimate {:.4f})'.\n",
    "          format(len(sample), 100 * cl, ci[0], ci[1], mean(sample)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, all intervals contain the true average (11.53). If we run this many times, we will come across cases where the interval doesn't contain 11.53. This may seem suspicious, but it is actually expected: it only means we see one of those remaining 5% of the cases.\n",
    "\n",
    "We can see here that the larger the sample, the smaller the interval. This also makes intuitive sense. Consider the edge cases. If we randomly choose a sample of size 1, the sample average (in this case simply the number of references of the chosen metadata record) will vary a lot, depending on the random choice. On the other hand, we can choose \"randomly\" a sample of size equal to the size of the entire dataset, and in this case the estimate will be identical to the true population average.\n",
    "\n",
    "### Sampling distribution\n",
    "\n",
    "So intuitively everything seems to work. But where does this magic interval actually come from? It is calculated by the theoretical analysis of the sampling distribution (not to be confused with sample distribution):\n",
    "  * **sample distribution** is when we collect one sample of size k and calculate our statistic for every element in the sample. It is a distribution of k values of the statistic value in the sample.\n",
    "  * **sampling distribution** is when we independently collect n samples, each of size k, and calculate the sample average for each sample. It is the distribution of n sample averages.\n",
    "\n",
    "Note that choosing randomly one sample of size k and calculating the sample average is equivalent to choosing randomly one value from the sampling distribution containing all possible samples of size k. [Central Limit Theorem](https://en.wikipedia.org/wiki/Central_limit_theorem) tells us that sampling distribution is approximately normal with the mean equal to the population mean. Of course, we do not know where in the sampling distribution our chosen sample average lies. Maybe we were lucky and our sample average is close to the middle of the sampling distribution, meaning that sample average is close to the population average. But it is also possible that our sample average is in the tail of the sampling distribution, far from the population average.\n",
    "\n",
    "Now let's assume we have decided on the confidence level 95%. We can say that we are 95% sure that our sample average lies within the middle 95% of the sampling distribution, that is within 2 standard deviations from the mean. Central Limit Theorem lets us calculate this standard deviation, which gives the upper bound on the distance from our sample mean to the mean of the sampling distribution. Since we know the distance, but not the direction, we obtain a confidence interval in the form (sample mean - 2 * stdev, sample mean + 2 * stdev). Different values of confidence level will give us different distances, but the principle remains the same.\n",
    "\n",
    "Let's now visualize the sampling distribution for some specific cases. We will generate histograms of sampling distributions for all combinations of n samples of size k, where n and k are the elements of the set {25, 50, 100, 200, 400}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sampling_distribution(sample_size, stat_fun, samples):\n",
    "    with Pool() as pool:\n",
    "        results = pool.starmap(get_sample_distribution, [(sample_size, stat_fun)] * samples)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [25, 50, 100, 200, 400]\n",
    "l = len(sizes)\n",
    "sampling_means = {s: {} for s in sizes}\n",
    "intervals = {s: {} for s in sizes}\n",
    "means = pd.DataFrame(numpy.zeros((l, l)), index=sizes, columns=sizes)\n",
    "stdevs = pd.DataFrame(numpy.zeros((l, l)), index=sizes, columns=sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 samples of size 25 each\n",
      "50 samples of size 25 each\n",
      "100 samples of size 25 each\n",
      "200 samples of size 25 each\n",
      "400 samples of size 25 each\n",
      "25 samples of size 50 each\n",
      "50 samples of size 50 each\n",
      "100 samples of size 50 each\n",
      "200 samples of size 50 each\n",
      "400 samples of size 50 each\n",
      "25 samples of size 100 each\n",
      "50 samples of size 100 each\n",
      "100 samples of size 100 each\n",
      "200 samples of size 100 each\n",
      "400 samples of size 100 each\n",
      "25 samples of size 200 each\n",
      "50 samples of size 200 each\n",
      "100 samples of size 200 each\n",
      "200 samples of size 200 each\n",
      "400 samples of size 200 each\n",
      "25 samples of size 400 each\n",
      "50 samples of size 400 each\n",
      "100 samples of size 400 each\n",
      "200 samples of size 400 each\n",
      "400 samples of size 400 each\n"
     ]
    }
   ],
   "source": [
    "for sample_size in sizes:\n",
    "    for samples in sizes:\n",
    "        print('{} samples of size {} each'.format(samples, sample_size))\n",
    "        distribution = get_sampling_distribution(sample_size, ref_count, samples)\n",
    "        sampling_means[sample_size][samples] = [mean(r) for r in distribution]\n",
    "        intervals[sample_size][samples] = [confidence_interval(r, .95) for r in distribution]\n",
    "        means.at[sample_size, samples] = mean(sampling_means[sample_size][samples])\n",
    "        stdevs.at[sample_size, samples] = stdev(sampling_means[sample_size][samples])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look first at the means of the sampling distributions for all combinations of n and k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>25</th>\n",
       "      <th>50</th>\n",
       "      <th>100</th>\n",
       "      <th>200</th>\n",
       "      <th>400</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>11.1008</td>\n",
       "      <td>13.51440</td>\n",
       "      <td>12.130800</td>\n",
       "      <td>11.975000</td>\n",
       "      <td>11.258800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>11.2424</td>\n",
       "      <td>10.65000</td>\n",
       "      <td>11.866400</td>\n",
       "      <td>12.144200</td>\n",
       "      <td>11.443550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>11.6500</td>\n",
       "      <td>11.81660</td>\n",
       "      <td>11.879400</td>\n",
       "      <td>11.768650</td>\n",
       "      <td>11.734525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>11.5852</td>\n",
       "      <td>11.89530</td>\n",
       "      <td>11.532900</td>\n",
       "      <td>11.703200</td>\n",
       "      <td>11.588612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>11.5700</td>\n",
       "      <td>11.84815</td>\n",
       "      <td>11.696125</td>\n",
       "      <td>11.565625</td>\n",
       "      <td>11.616975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         25        50         100        200        400\n",
       "25   11.1008  13.51440  12.130800  11.975000  11.258800\n",
       "50   11.2424  10.65000  11.866400  12.144200  11.443550\n",
       "100  11.6500  11.81660  11.879400  11.768650  11.734525\n",
       "200  11.5852  11.89530  11.532900  11.703200  11.588612\n",
       "400  11.5700  11.84815  11.696125  11.565625  11.616975"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They seem fairly close to the true population average, perhaps with some outliers. We can also observe that the larger the sample size, the closer we get to the population average.\n",
    "\n",
    "Now let's see the standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>25</th>\n",
       "      <th>50</th>\n",
       "      <th>100</th>\n",
       "      <th>200</th>\n",
       "      <th>400</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3.823787</td>\n",
       "      <td>10.373892</td>\n",
       "      <td>6.678813</td>\n",
       "      <td>5.602582</td>\n",
       "      <td>4.742486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>3.039086</td>\n",
       "      <td>3.124242</td>\n",
       "      <td>3.971179</td>\n",
       "      <td>3.926660</td>\n",
       "      <td>3.501269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2.410608</td>\n",
       "      <td>2.878438</td>\n",
       "      <td>2.708557</td>\n",
       "      <td>2.857785</td>\n",
       "      <td>2.900598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1.852987</td>\n",
       "      <td>1.941922</td>\n",
       "      <td>1.779637</td>\n",
       "      <td>1.897400</td>\n",
       "      <td>1.834247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>1.240678</td>\n",
       "      <td>2.013222</td>\n",
       "      <td>1.429738</td>\n",
       "      <td>1.254623</td>\n",
       "      <td>1.269894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          25         50        100       200       400\n",
       "25   3.823787  10.373892  6.678813  5.602582  4.742486\n",
       "50   3.039086   3.124242  3.971179  3.926660  3.501269\n",
       "100  2.410608   2.878438  2.708557  2.857785  2.900598\n",
       "200  1.852987   1.941922  1.779637  1.897400  1.834247\n",
       "400  1.240678   2.013222  1.429738  1.254623  1.269894"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stdevs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard deviation of the sampling distribution depends heavily on the sample size. The larger the size, the lower the standard deviation. This confirms the previous observation: the larger the sample size, the narrower the confidence interval will be.\n",
    "\n",
    "Finally, let's plot the histograms of the sampling distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 25 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axes = plt.subplots(5, 5, sharex=True, figsize=(10, 8))\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        axes[i, j].hist(sampling_means[sizes[i]][sizes[j]], bins=30)\n",
    "        axes[i, j].xaxis.set_ticks_position('none')\n",
    "        axes[i, j].yaxis.set_ticks_position('none')\n",
    "        axes[i, j].set_xticklabels([])\n",
    "        axes[i, j].set_yticklabels([])\n",
    "        axes[i, j].set_xlim(0, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histograms also confirm our observations about the means and standard deviations of the sampling distributions. As we increase the number of samples (from left to right in the plot), the sampling distribution becomes more and more normal. As we increase the sample size (from top to bottom in the plot), the sampling distribution becomes narrower (standard deviation decreases).\n",
    "\n",
    "We can also calculate for every sampling distribution the percentage of intervals that do not contain the true population average (11.53):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "25 samples of size 25 each\n",
      "0.0% of confidence intervals does not contain the true average\n",
      "\n",
      "50 samples of size 25 each\n",
      "6.0% of confidence intervals does not contain the true average\n",
      "\n",
      "100 samples of size 25 each\n",
      "7.0% of confidence intervals does not contain the true average\n",
      "\n",
      "200 samples of size 25 each\n",
      "6.5% of confidence intervals does not contain the true average\n",
      "\n",
      "400 samples of size 25 each\n",
      "11.5% of confidence intervals does not contain the true average\n",
      "\n",
      "25 samples of size 50 each\n",
      "8.0% of confidence intervals does not contain the true average\n",
      "\n",
      "50 samples of size 50 each\n",
      "14.0% of confidence intervals does not contain the true average\n",
      "\n",
      "100 samples of size 50 each\n",
      "11.0% of confidence intervals does not contain the true average\n",
      "\n",
      "200 samples of size 50 each\n",
      "8.0% of confidence intervals does not contain the true average\n",
      "\n",
      "400 samples of size 50 each\n",
      "10.5% of confidence intervals does not contain the true average\n",
      "\n",
      "25 samples of size 100 each\n",
      "8.0% of confidence intervals does not contain the true average\n",
      "\n",
      "50 samples of size 100 each\n",
      "12.0% of confidence intervals does not contain the true average\n",
      "\n",
      "100 samples of size 100 each\n",
      "10.0% of confidence intervals does not contain the true average\n",
      "\n",
      "200 samples of size 100 each\n",
      "7.5% of confidence intervals does not contain the true average\n",
      "\n",
      "400 samples of size 100 each\n",
      "8.5% of confidence intervals does not contain the true average\n",
      "\n",
      "25 samples of size 200 each\n",
      "4.0% of confidence intervals does not contain the true average\n",
      "\n",
      "50 samples of size 200 each\n",
      "2.0% of confidence intervals does not contain the true average\n",
      "\n",
      "100 samples of size 200 each\n",
      "5.0% of confidence intervals does not contain the true average\n",
      "\n",
      "200 samples of size 200 each\n",
      "5.0% of confidence intervals does not contain the true average\n",
      "\n",
      "400 samples of size 200 each\n",
      "7.0% of confidence intervals does not contain the true average\n",
      "\n",
      "25 samples of size 400 each\n",
      "0.0% of confidence intervals does not contain the true average\n",
      "\n",
      "50 samples of size 400 each\n",
      "8.0% of confidence intervals does not contain the true average\n",
      "\n",
      "100 samples of size 400 each\n",
      "10.0% of confidence intervals does not contain the true average\n",
      "\n",
      "200 samples of size 400 each\n",
      "7.0% of confidence intervals does not contain the true average\n",
      "\n",
      "400 samples of size 400 each\n",
      "7.2% of confidence intervals does not contain the true average\n"
     ]
    }
   ],
   "source": [
    "for sample_size in sizes:\n",
    "    for samples in sizes:\n",
    "        print('\\n{} samples of size {} each'.format(samples, sample_size))\n",
    "        outside = len([i for i in intervals[sample_size][samples] if 11.53 < i[0] or 11.53 > i[1]])/samples\n",
    "        print('{:.1f}% of confidence intervals does not contain the true average'.format(100 * outside))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is still some randomness here, but in general the fractions seems low. Confidence intervals are of course calculated for much higher numbers of samples than we have here.\n",
    "\n",
    "Note also that instead of using the equation, we could calculate the confidence interval experimentally. We could simply draw n samples of size k, calculate the mean sample statistic for every sample, and then treat the middle 95% of this sampling distribution as the confidence interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating the average search rank\n",
    "\n",
    "Let's try a different statistic. It will be the rank of the metadata record in the result list, returned when we perform a metadata search using the record's title (without any modifications). Statistically speaking, the main difference from the number of the references is that the new statistic is much more skewed. Typically in the sample we will have a lot of 1s, and rarely an outlier with a high value. To save time iterating through the results list, I truncate the rank at 100. 100 is also returned if there is not title or if the title is empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example sample distribution: 1 1 1 1 1 1 1 1 1 100 1 1 1 1 100 3 1 1 1 100 2 1 1 100 1 100 1 3 1 63 1 1 11 1 1 100 1 1 1 100 1 100 2 1 1 1 1 2 5 1 1 9 1 1 1 1 1 100 2 1 46 41 1 21 2 2 1 100 1 1 1 1 1 1 1 1 1 100 1 3 1 1 1 1 1 1 100 1 1 74 1 2 1 100 1 1 1 100 8 1\n",
      "Based on the sample of size 20, we are 95.0% sure that the population average is in the range -3.8893-16.7893 (estimate 6.4500)\n",
      "Based on the sample of size 50, we are 95.0% sure that the population average is in the range 4.8556-23.3444 (estimate 14.1000)\n",
      "Based on the sample of size 100, we are 95.0% sure that the population average is in the range 6.2676-17.3124 (estimate 11.7900)\n",
      "Based on the sample of size 200, we are 95.0% sure that the population average is in the range 12.1098-21.9302 (estimate 17.0200)\n",
      "Based on the sample of size 400, we are 95.0% sure that the population average is in the range 12.3452-19.0098 (estimate 15.6775)\n",
      "Based on the sample of size 800, we are 95.0% sure that the population average is in the range 12.4606-17.0094 (estimate 14.7350)\n",
      "Based on the sample of size 1600, we are 95.0% sure that the population average is in the range 12.7942-15.9895 (estimate 14.3919)\n"
     ]
    }
   ],
   "source": [
    "def search_rank_by_title(work):\n",
    "    if 'title' not in work:\n",
    "        return 100\n",
    "    if not work['title']:\n",
    "        return 100\n",
    "    title = work['title'][0]\n",
    "    if not title:\n",
    "        return 100\n",
    "    for i, w in enumerate(works.query(title).sort('relevance')):\n",
    "        if i > 100:\n",
    "            return 100\n",
    "        if w['DOI'] == work['DOI']:\n",
    "            return i+1\n",
    "    return 100\n",
    "\n",
    "sample = get_sample_distribution(100, search_rank_by_title)\n",
    "print('Example sample distribution: ' + ' '.join([str(s) for s in sample]))\n",
    "\n",
    "for size in [20, 50, 100, 200, 400, 800, 1600]:\n",
    "    sample = get_sample_distribution(size, search_rank_by_title)\n",
    "    ci = confidence_interval(sample, cl)\n",
    "    print('Based on the sample of size {}, we are {}% sure that the population average is in the range {:.4f}-{:.4f} (estimate {:.4f})'.\n",
    "          format(len(sample), 100 * cl, ci[0], ci[1], mean(sample)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, some important things to remember:\n",
    "  * (Lack of) certainty. Remember that the confidence level < 1. This means, we are never sure that our confidence interval contains the population average. With the confidence level of 95%, if we chose a sample 100 times, just by chance we would get intervals not containing the population average in approximately 5 cases. If for any reason you need to be 100% sure, just process the entire dataset.\n",
    "  * Randomness. The sample has to be chosen randomly. So no \"first 1000 records from the snapshot\". Note how different the partial average numbers of references were from the final number, as I was processing the entire dataset.\n",
    "  * Sample size. We know already that the larger the sample, the better. As a rule of thumb, using sample sizes < 30 makes the estimates, including the interval, pretty unreliable. The reason is that the standard deviation used for all calculations is obtained from the sample, and it becomes unreliable when the size is small. Also, the more skewed the statistic distribution, the larger sample we need. I used rather small sizes in this notebook, but in general I suggest counting in thousands.\n",
    "  * Generalization. The sample average can be used as an estimate for the population average, but only the population it was drawn from. This means that if we apply any filters before sampling (which is equivalent to sampling from a subset passing the filter), we can reason only about the filtered subset of the data.\n",
    "  * Averaging. The whole thing only works with averages (and sums). It doesn't work for other aggregate functions. Note that a proportion of records passing a certain filter can be estimated, if we treat it as an average of 0's (doesn't pass) and 1's (passes).\n",
    "  * Reproducibility. This is more of an engineering concern. In short, all the analyses we do should be reproducible. In the context of sampling it means, at the very least, that we should record the samples obtained from the API."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
